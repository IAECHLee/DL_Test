"""
PatchCore ì´ìƒ íƒì§€ ëª¨ë¸ êµ¬í˜„
torchvision ResNet ë°±ë³¸ì„ ì‚¬ìš©í•œ PatchCore ëª¨ë¸
"""

import torch
import torch.nn as nn
import torchvision.transforms as T
import numpy as np
import cv2
import os
from typing import List, Tuple, Dict, Optional, Any
from pathlib import Path
from sklearn.metrics import roc_auc_score
from sklearn.neighbors import NearestNeighbors
import pickle

from base_model import BaseAnomalyModel


class FeatureExtractor(nn.Module):
    """ResNet ë°±ë³¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
    
    def __init__(self, backbone_name: str = 'wide_resnet50_2', layers: List[str] = None):
        super().__init__()
        
        if layers is None:
            layers = ['layer3']
            
        # ResNet ë°±ë³¸ ë¡œë“œ
        if backbone_name == 'wide_resnet50_2':
            import torchvision.models as models
            self.backbone = models.wide_resnet50_2(pretrained=True)
        else:
            raise ValueError(f"Unsupported backbone: {backbone_name}")
        
        self.layers = layers
        self.features = {}
        
        # íŠ¹ì§• ì¶”ì¶œ í›„í¬ ë“±ë¡
        self._register_hooks()
        self.backbone.eval()
        
    def _register_hooks(self):
        """íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ í›„í¬ ë“±ë¡"""
        def hook_fn(name):
            def hook(module, input, output):
                self.features[name] = output
            return hook
        
        for name in self.layers:
            if hasattr(self.backbone, name):
                getattr(self.backbone, name).register_forward_hook(hook_fn(name))
    
    def forward(self, x):
        """ìˆœì „íŒŒ ë° íŠ¹ì§• ì¶”ì¶œ"""
        self.features.clear()
        with torch.no_grad():
            _ = self.backbone(x)
        return self.features.copy()


class PatchCoreModel(BaseAnomalyModel):
    """GPU ìµœì í™”ëœ PatchCore ëª¨ë¸"""
    
    def __init__(self, device: torch.device, config: Optional[Dict] = None):
        super().__init__(device)
        self.model_name = "PatchCore"
        
        # ê¸°ë³¸ ì„¤ì •
        default_config = {
            'backbone': 'wide_resnet50_2',
            'layers': ['layer3'],
            'input_size': (224, 224),
            'normalization_mean': [0.485, 0.456, 0.406],
            'normalization_std': [0.229, 0.224, 0.225],
            'k_nearest_neighbors': 9,
            'coreset_sampling_ratio': 0.1,
            'batch_size': 8,
            'resolution_ratio': 0.35
        }
        
        if config:
            default_config.update(config)
        self.config = default_config
        
        # í•´ìƒë„ ë¹„ìœ¨ ì„¤ì •
        self.resolution_ratio = self.config['resolution_ratio']
        
        print(f"âš¡ [PatchCore] Device: {self.device}")
        print(f"ğŸ“ [Resolution] Target ratio: {self.resolution_ratio*100:.0f}%")
        
        self.feature_extractor = None
        self.transform = None
        self.memory_bank_gpu = None
        self.memory_bank_cpu = None
        self.nn_index = None
        
    def build_model(self) -> None:
        """ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬ì„±"""
        # íŠ¹ì§• ì¶”ì¶œê¸° ì´ˆê¸°í™”
        self.feature_extractor = FeatureExtractor(
            self.config['backbone'], 
            self.config['layers']
        ).to(self.device)
        
        # ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        self.transform = T.Compose([
            T.Resize(self.config['input_size']),
            T.ToTensor(),
            T.Normalize(
                mean=self.config['normalization_mean'], 
                std=self.config['normalization_std']
            )
        ])
        
        print(f"ğŸ§  [PatchCore] Built with {self.config['backbone']}")
        print(f"ğŸ¯ [PatchCore] Target layers: {self.config['layers']}")
    
    def preprocess_images_batch(self, images: List[np.ndarray]) -> torch.Tensor:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        batch_tensors = []
        
        for image in images:
            # RGB ë³€í™˜
            if len(image.shape) == 3 and image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # í•´ìƒë„ ë³´ì¡´ ë¦¬ì‚¬ì´ì¦ˆ
            patches = self.resize_with_aspect_ratio(image, self.config['input_size'])
            
            # ê° íŒ¨ì¹˜ë¥¼ í…ì„œë¡œ ë³€í™˜
            for patch in patches:
                tensor_img = torch.from_numpy(patch).permute(2, 0, 1).float() / 255.0
                
                # ì •ê·œí™”
                for i, (mean, std) in enumerate(zip(
                    self.config['normalization_mean'], 
                    self.config['normalization_std']
                )):
                    tensor_img[i] = (tensor_img[i] - mean) / std
                    
                batch_tensors.append(tensor_img)
        
        return torch.stack(batch_tensors).to(self.device)
    
    def resize_with_aspect_ratio(self, image: np.ndarray, target_size: Tuple[int, int]) -> List[np.ndarray]:
        """ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì›ë³¸ í•´ìƒë„ë¥¼ ë³´ì¡´í•˜ëŠ” íŒ¨ì¹˜ ë°©ì‹"""
        h, w = image.shape[:2]
        target_w, target_h = target_size
        
        # ì„¤ì •ëœ í•´ìƒë„ ë¹„ìœ¨ ì‚¬ìš©
        min_resolution_ratio = self.resolution_ratio
        original_pixels = h * w
        target_total_pixels = original_pixels * min_resolution_ratio
        
        # í•„ìš”í•œ íŒ¨ì¹˜ ê°œìˆ˜ ê³„ì‚°
        min_patches = max(1, int(np.ceil(target_total_pixels / (target_w * target_h))))
        
        # ì¢…íš¡ë¹„ë¥¼ ê³ ë ¤í•œ íŒ¨ì¹˜ ë°°ì¹˜
        aspect_ratio = w / h
        
        if aspect_ratio > 1:  # ê°€ë¡œê°€ ê¸´ ì´ë¯¸ì§€
            patch_cols = max(1, int(np.ceil(np.sqrt(min_patches * aspect_ratio))))
            patch_rows = max(1, int(np.ceil(min_patches / patch_cols)))
        else:  # ì„¸ë¡œê°€ ê¸´ ì´ë¯¸ì§€  
            patch_rows = max(1, int(np.ceil(np.sqrt(min_patches / aspect_ratio))))
            patch_cols = max(1, int(np.ceil(min_patches / patch_rows)))
        
        # íŒ¨ì¹˜ ìƒì„±
        patches = []
        patch_w = w // patch_cols
        patch_h = h // patch_rows
        
        for i in range(patch_rows):
            for j in range(patch_cols):
                y1 = i * patch_h
                y2 = min((i + 1) * patch_h, h)
                x1 = j * patch_w  
                x2 = min((j + 1) * patch_w, w)
                
                patch = image[y1:y2, x1:x2]
                resized_patch = cv2.resize(patch, target_size)
                patches.append(resized_patch)
        
        return patches
    
    def train(self, 
             normal_images: torch.Tensor, 
             progress_callback: Optional[callable] = None) -> Dict[str, Any]:
        """ëª¨ë¸ í•™ìŠµ (ì •ìƒ ì´ë¯¸ì§€ë¡œ ë©”ëª¨ë¦¬ ë±…í¬ êµ¬ì„±)"""
        if self.feature_extractor is None:
            self.build_model()
            
        self.feature_extractor.eval()
        all_features = []
        
        total_batches = len(normal_images)
        
        with torch.no_grad():
            for i, batch in enumerate(normal_images):
                if isinstance(batch, list):
                    # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì´ë¯¸ì§€ë“¤ì„ ë°°ì¹˜ë¡œ ë³€í™˜
                    batch_tensor = self.preprocess_images_batch(batch)
                else:
                    batch_tensor = batch.to(self.device)
                
                # íŠ¹ì§• ì¶”ì¶œ
                features_dict = self.feature_extractor(batch_tensor)
                
                # ëª¨ë“  ë ˆì´ì–´ì˜ íŠ¹ì§•ì„ ê²°í•©
                batch_features = []
                for layer_name in self.config['layers']:
                    if layer_name in features_dict:
                        feat = features_dict[layer_name]
                        # íŠ¹ì§•ì„ í‰íƒ„í™”
                        feat_flat = feat.reshape(feat.size(0), feat.size(1), -1)
                        feat_flat = feat_flat.permute(0, 2, 1)  # [B, H*W, C]
                        batch_features.append(feat_flat.reshape(-1, feat.size(1)))
                
                if batch_features:
                    combined_features = torch.cat(batch_features, dim=0)
                    all_features.append(combined_features.cpu())
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                self.clear_memory()
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if progress_callback:
                    progress = int((i + 1) / total_batches * 100)
                    progress_callback(progress)
        
        # ë©”ëª¨ë¦¬ ë±…í¬ êµ¬ì„±
        if all_features:
            memory_bank = torch.cat(all_features, dim=0)
            
            # ì½”ì–´ì…‹ ìƒ˜í”Œë§
            if len(memory_bank) > 1000:  # ë„ˆë¬´ ë§ì€ íŠ¹ì§•ì´ ìˆìœ¼ë©´ ìƒ˜í”Œë§
                sample_size = min(len(memory_bank), 
                                int(len(memory_bank) * self.config['coreset_sampling_ratio']))
                indices = torch.randperm(len(memory_bank))[:sample_size]
                memory_bank = memory_bank[indices]
            
            self.memory_bank_cpu = memory_bank
            self.memory_bank_gpu = memory_bank.to(self.device)
            
            # k-NN ì¸ë±ìŠ¤ êµ¬ì„±
            self.nn_index = NearestNeighbors(
                n_neighbors=self.config['k_nearest_neighbors'],
                metric='cosine'
            )
            self.nn_index.fit(memory_bank.numpy())
            
            self.is_trained = True
            
            print(f"âœ… [PatchCore] í•™ìŠµ ì™„ë£Œ - ë©”ëª¨ë¦¬ ë±…í¬ í¬ê¸°: {len(memory_bank)}")
            
            return {
                'status': 'success',
                'memory_bank_size': len(memory_bank),
                'feature_dim': memory_bank.shape[1]
            }
        else:
            return {'status': 'failed', 'error': 'No features extracted'}
    
    def predict(self, images: torch.Tensor) -> Tuple[np.ndarray, np.ndarray]:
        """ì´ìƒ íƒì§€ ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("Model must be trained before prediction")
            
        self.feature_extractor.eval()
        anomaly_scores = []
        anomaly_maps = []
        
        with torch.no_grad():
            for batch in images:
                if isinstance(batch, list):
                    batch_tensor = self.preprocess_images_batch(batch)
                else:
                    batch_tensor = batch.to(self.device)
                
                # íŠ¹ì§• ì¶”ì¶œ
                features_dict = self.feature_extractor(batch_tensor)
                
                # ì´ìƒ ì ìˆ˜ ê³„ì‚°
                for layer_name in self.config['layers']:
                    if layer_name in features_dict:
                        feat = features_dict[layer_name]
                        
                        # íŠ¹ì§• í‰íƒ„í™”
                        B, C, H, W = feat.shape
                        feat_flat = feat.reshape(B, C, -1).permute(0, 2, 1)  # [B, H*W, C]
                        
                        for b in range(B):
                            single_feat = feat_flat[b].cpu().numpy()  # [H*W, C]
                            
                            # k-NN ê±°ë¦¬ ê³„ì‚°
                            distances, _ = self.nn_index.kneighbors(single_feat)
                            scores = distances.mean(axis=1)  # [H*W]
                            
                            # ì´ìƒ ë§µ ë³µì›
                            anomaly_map = scores.reshape(H, W)
                            anomaly_maps.append(anomaly_map)
                            
                            # ì „ì²´ ì´ìƒ ì ìˆ˜
                            anomaly_scores.append(scores.max())
                
                self.clear_memory()
        
        return np.array(anomaly_scores), np.array(anomaly_maps)
    
    def save_model(self, save_dir: Path) -> str:
        """ëª¨ë¸ ì €ì¥"""
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'config': self.config,
            'memory_bank': self.memory_bank_cpu,
            'is_trained': self.is_trained,
            'model_name': self.model_name
        }
        
        if self.nn_index is not None:
            model_data['nn_index'] = self.nn_index
        
        save_path = save_dir / 'patchcore_model.pkl'
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ’¾ [PatchCore] ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
        return str(save_path)
    
    def load_model(self, model_path: Path) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.config.update(model_data['config'])
            self.memory_bank_cpu = model_data['memory_bank']
            self.is_trained = model_data['is_trained']
            
            if self.memory_bank_cpu is not None:
                self.memory_bank_gpu = self.memory_bank_cpu.to(self.device)
            
            if 'nn_index' in model_data:
                self.nn_index = model_data['nn_index']
            
            # ëª¨ë¸ ì¬êµ¬ì„±
            self.build_model()
            
            print(f"ğŸ“‚ [PatchCore] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            return True
            
        except Exception as e:
            print(f"âŒ [PatchCore] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
